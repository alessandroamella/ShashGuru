services:
  frontend:
    env_file:
      - .env
    build:
      context: .
      dockerfile: frontend/Dockerfile
    ports:
      # default to FRONTEND_PORT or 8080
      - "${FRONTEND_PORT:-8080}:80"
      # Frontend no longer proxies the AI
    restart: unless-stopped
    volumes:
      - ./config/nginx_ai_pc.conf:/etc/nginx/nginx.conf:ro
      - ./logs/nginx:/var/log/nginx
    logging:
      driver: "json-file"
      options:
        max-size: "30m"
        max-file: "3"
    depends_on:
      - backend

  backend:
    env_file:
      - .env
    build:
      context: .
      dockerfile: backend/Dockerfile
    # Remove volumes binding for production so code is baked into the image
    restart: unless-stopped
    # expose this too
    ports:
      - "${BACKEND_PORT:-5000}:5000"
    environment:
      - FLASK_ENV=production
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      # External AI services
      - GROQ_API_KEY=${GROQ_API_KEY}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - DEFAULT_LLM_MODEL=${DEFAULT_LLM_MODEL:-llama-3.1-8b-instant}
      - USE_CLOUD_AI=true
      # Chess engine settings
      - ENGINE_POOL_SIZE=${ENGINE_POOL_SIZE:-4}
      - CPU_COUNT=${CPU_COUNT:-4}
    logging:
      driver: "json-file"
      options:
        max-size: "30m"
        max-file: "3"
    depends_on:
      - redis

  redis:
    image: redis:7-alpine
    volumes:
      # TODO: Should we keep data at closing?
      - redis-data:/data
    command: redis-server --appendonly yes --appendfsync everysec
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "30m"
        max-file: "3"

volumes:
  redis-data:
